{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2_1_TinymlParadigm",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hewp84/tinyml/blob/main/2_1_TinymlParadigm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<table><tr>\n",
        "    <td  style=\"background-color:#ffffff;text-align:left;\"><a href=\"http://www.purdue.edu\" target=\"_blank\"><img src=\"https://github.com/hewp84/tinyml/blob/main/img/Logo-Purdue-University.png?raw=1\" width=\"30%\" align=\"left\"></a></td>\n",
        "    <td style=\"background-color:#ffffff;\">&nbsp;</td>\n",
        "    <td style=\"background-color:#ffffff;vertical-align:text-middle;text-align:right;\">\n",
        "        <table><tr style=\"background-color:white;\">\n",
        "            <td><h1 style=\"font-size:10vw\">TinyML for Manufacturing</h1></td>\n",
        "            <td>\n",
        "        </tr></table>\n",
        "    </td>     \n",
        "</tr></table>"
      ],
      "metadata": {
        "id": "mLvWDZC0UUPh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Shift of Machine Learning\n",
        "\n",
        "##Learning Goal\n",
        "You will be able to apply the Machine Learning paradigm to train a model\n",
        "\n",
        "You will be able to evaluate the loss function in a trained model\n",
        "\n",
        "You will be able to contrast between underfitted, overfitted, and well-fitted trained models"
      ],
      "metadata": {
        "id": "2bfsLoHuhhRi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Machine learning figures things out on its own. Compare the traditional programming paradigm to the machine learning paradigm below."
      ],
      "metadata": {
        "id": "AfGrrxwbPvG3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![picture](https://github.com/hewp84/tinyml/blob/main/img/Screenshot%202022-02-03%20114832.jpg?raw=1)\n",
        "<font size='1'>Figure 1: TP vs ML paradigm<sup>1</sup></font>"
      ],
      "metadata": {
        "id": "m6o_HGX8Wst2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For a Machine Learning algorithm to solve a problem, there are two key features. (1) it will take a piece of **data** and (2) will take a **guess** at the **answer**. Then, it will *optimize* its **guess** until it gets the correct **answer**. The concept of *loss* will be what helps to *optimize* the **guess**. \n",
        "\n",
        "To illustrate, the below diagram shows the general machine learning process."
      ],
      "metadata": {
        "id": "mlV5fjIzXQwD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://github.com/hewp84/tinyml/blob/main/img/Screenshot%202022-02-03%20163227.jpg?raw=1\" width=\"825\" height=\"325\"/>\n",
        "<br><font size='1'>Figure 2: ML paradigm process<sup>1</sup></font>\n"
      ],
      "metadata": {
        "id": "Nw36UX7Objia"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Simulating a Machine Learning model to understand *loss*\n",
        "\n",
        "Here we will iterate through, by trial and error, different **rules** (the \"output\" or \"result\" in the ML paradigm) to understand why machine learning is so powerful, and principly lies on the concept of **loss**<br>\n",
        "<br>\n",
        "We are given a set of **data** in the form of **x** values that we will work with. And, a set of answers (**y** values) that correspond to the data.\n"
      ],
      "metadata": {
        "id": "2IEdL8P1TAUo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = [-1, 0, 1, 2, 3, 4]                    # input values\n",
        "y = [-3, -1, 1, 3, 5, 7]                   # output, or, \"answer\" values"
      ],
      "metadata": {
        "id": "ChErAapYYhMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For any piece of **data** (**x**-value, input), we should be able to figure out the **answer**. <br>"
      ],
      "metadata": {
        "id": "Ne3bahpOUPNU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Guessing the rule ourselves\n",
        "We need a **rule** (the function that will provide the answer for the given input). For our simple example, this rule will be a linear function in the form of **y=mx+b**.\n",
        "\n",
        "Shown below is a slider to adjust different 'm' and 'b' values so that we can demonstrate how good or bad rules are at predicting (drawing inferences) about the answer.\n",
        "\n",
        "By default, m = 3 and b = -1. <br>\n",
        "\n",
        "#### The graph below illustrates loss\n",
        "The <font color=\"green\"> green </font> line shows the real and accurate values that correlate our **x** to our **y**. The <font color=\"red\"> red </font> line shows the values that are predicted based on our rule that is defined by our slider. The **loss** is visualized by the space between the two lines.\n",
        "<br>\n",
        "\n",
        "Run the cell below and then play around by changing the **m** value on the slider and the graph will update automatically."
      ],
      "metadata": {
        "id": "UU2NKWnBWFA_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Change the values to explore how loss changes {display-mode:\"form\", run:\"auto\"}\n",
        "\n",
        "m = 2       #@param {type:\"slider\", min:-25, max:25, step:1}\n",
        "b = 1       #@param {type:\"slider\", min:-25, max:25, step:1}\n",
        "\n",
        "import math\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plot\n",
        "plot.style.use('seaborn-whitegrid')\n",
        "import numpy as np\n",
        "\n",
        "# the following calculates e\n",
        "guessY = []\n",
        "for iX in x:\n",
        "  iY = (m*iX) + b\n",
        "  guessY.append(iY)\n",
        "\n",
        "total_square_error = 0\n",
        "for i in range(0, len(y)):\n",
        "  square_error = (y[i] - guessY[i]) ** 2\n",
        "  total_square_error += square_error\n",
        "\n",
        "print(\"The predicted Y is: \" + str(guessY) + \"\\n\")\n",
        "print(\"The loss for this guess is: \" + str(math.sqrt(total_square_error)))\n",
        "\n",
        "fig, ax = plot.subplots()\n",
        "ax.plot(x, y, marker='o', color='green', label='Real values')\n",
        "ax.plot(x, guessY, marker='^', color='red', label='Predicted values')\n",
        "leg = ax.legend()\n",
        "ax.legend(loc='upper left')\n",
        "\n",
        "total_square_error = 0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "RFl9HovEjNDU",
        "outputId": "5846b283-5910-4f9a-df35-0c4c6e2c525a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The predicted Y is: [-1, 1, 3, 5, 7, 9]\n",
            "\n",
            "The loss for this guess is: 4.898979485566356\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The Reality\n",
        "\n",
        "This is a very trivial process. It is not too hard to find that m=2 and b=-1 (y = 2x-1) is the correct rule to match the **x** values to the **y** values. \n",
        "\n",
        "<br>\n",
        "\n",
        "However, with more complex data, figuring out those values for the rule is not so easy. Machine learning helps us out. By taking a guess, measuring our accuracy, and optimizing our guess *again* and *again*, <font color='red'>we can produce a **model** that will provide accurate **inferences** from any **data**. </font>\n",
        "\n",
        "<img src=\"https://github.com/hewp84/tinyml/blob/main/img/Screenshot%202022-02-10%20093032.jpg?raw=1\" width=\"490\" height=\"159\"/> <br>\n",
        "<font size='1'>Figure 3: A \"model\"<sup>1</sup></font>"
      ],
      "metadata": {
        "id": "5VPV_yjWkkX2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Machine Learning\n",
        "\n",
        "Instead of simulating the machine learning process as we did above, now we will let the machine do the guessing, measuring, optimizing, and *learning*.\n",
        "\n",
        "The following block of code defines a simple neural network that will utilize the same **x** and **y** value. Each **epoch** that it lists is a **guess** that it took. For each epoch it calculates the **loss** and shows that as well. On each new guess that the ML algorithm takes, it tries to further minimize loss down to 0."
      ],
      "metadata": {
        "id": "IoB29vdZTiEv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "\n",
        "from google.colab.output import eval_js\n",
        "eval_js('google.colab.output.setIframeHeight(\"270\")')\n",
        "\n",
        "# define a neural network with one neuron\n",
        "# for more information on TF functions see: https://www.tensorflow.org/api_docs\n",
        "model = tf.keras.Sequential([keras.layers.Dense(units=1, input_shape=[1])])\n",
        "\n",
        "# use stochastic gradient descent for optimization and\n",
        "# the mean squared error loss function\n",
        "model.compile(optimizer='sgd', loss='mean_squared_error')\n",
        "\n",
        "# define some training data (xs as inputs and ys as outputs)\n",
        "xs = np.array([-1.0,  0.0, 1.0, 2.0, 3.0, 4.0], dtype=float)\n",
        "ys = np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0], dtype=float)\n",
        "\n",
        "# fit the model to the data (aka train the model)\n",
        "#@title ####Enter the number of epochs to train the model on and explore how the final loss value changes {run: \"auto\"}\n",
        "#@markdown ----\n",
        "#@markdown <br>\n",
        "Epochs = 500 #@param [10, 25, 50, 100, 500] {type: \"raw\"}\n",
        "\n",
        "history = model.fit(xs, ys, epochs=int(Epochs))\n",
        "\n",
        "#code for the loss graph\n",
        "train_loss = history.history['loss']\n",
        "#plots the x value from 0 to the # of epochs, loss values on the y-axis\n",
        "plot.plot((range(0, Epochs)), train_loss, 'g', label='Training loss')\n",
        "plot.xlabel('Epochs')\n",
        "plot.ylabel('Loss')\n",
        "plot.legend()"
      ],
      "metadata": {
        "id": "8QDC7y8voI5r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "outputId": "994a02e9-8db7-49f6-d1a2-f75a2e486ba1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "1/1 [==============================] - 0s 241ms/step - loss: 30.0779\n",
            "Epoch 2/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 23.9770\n",
            "Epoch 3/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 19.1708\n",
            "Epoch 4/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 15.3831\n",
            "Epoch 5/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 12.3970\n",
            "Epoch 6/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 10.0417\n",
            "Epoch 7/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.1826\n",
            "Epoch 8/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.7143\n",
            "Epoch 9/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.5533\n",
            "Epoch 10/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.6344\n",
            "Epoch 11/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 3.9060\n",
            "Epoch 12/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 3.3276\n",
            "Epoch 13/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 2.8673\n",
            "Epoch 14/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 2.5000\n",
            "Epoch 15/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.2060\n",
            "Epoch 16/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.9698\n",
            "Epoch 17/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.7792\n",
            "Epoch 18/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.6245\n",
            "Epoch 19/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.4982\n",
            "Epoch 20/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.3943\n",
            "Epoch 21/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.3081\n",
            "Epoch 22/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.2360\n",
            "Epoch 23/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1750\n",
            "Epoch 24/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1228\n",
            "Epoch 25/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0777\n",
            "Epoch 26/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0382\n",
            "Epoch 27/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0033\n",
            "Epoch 28/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.9719\n",
            "Epoch 29/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9435\n",
            "Epoch 30/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9175\n",
            "Epoch 31/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.8934\n",
            "Epoch 32/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.8710\n",
            "Epoch 33/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.8498\n",
            "Epoch 34/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.8298\n",
            "Epoch 35/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.8108\n",
            "Epoch 36/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7925\n",
            "Epoch 37/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.7750\n",
            "Epoch 38/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.7581\n",
            "Epoch 39/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7418\n",
            "Epoch 40/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7260\n",
            "Epoch 41/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7106\n",
            "Epoch 42/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6956\n",
            "Epoch 43/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6810\n",
            "Epoch 44/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6668\n",
            "Epoch 45/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6529\n",
            "Epoch 46/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6394\n",
            "Epoch 47/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6261\n",
            "Epoch 48/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6132\n",
            "Epoch 49/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6005\n",
            "Epoch 50/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5881\n",
            "Epoch 51/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5760\n",
            "Epoch 52/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5641\n",
            "Epoch 53/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5525\n",
            "Epoch 54/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5411\n",
            "Epoch 55/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5300\n",
            "Epoch 56/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5191\n",
            "Epoch 57/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5084\n",
            "Epoch 58/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4980\n",
            "Epoch 59/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4878\n",
            "Epoch 60/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4777\n",
            "Epoch 61/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4679\n",
            "Epoch 62/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4583\n",
            "Epoch 63/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.4489\n",
            "Epoch 64/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4397\n",
            "Epoch 65/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4306\n",
            "Epoch 66/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4218\n",
            "Epoch 67/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4131\n",
            "Epoch 68/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4046\n",
            "Epoch 69/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3963\n",
            "Epoch 70/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.3882\n",
            "Epoch 71/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3802\n",
            "Epoch 72/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.3724\n",
            "Epoch 73/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3647\n",
            "Epoch 74/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.3572\n",
            "Epoch 75/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.3499\n",
            "Epoch 76/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3427\n",
            "Epoch 77/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3357\n",
            "Epoch 78/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.3288\n",
            "Epoch 79/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.3220\n",
            "Epoch 80/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3154\n",
            "Epoch 81/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3089\n",
            "Epoch 82/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.3026\n",
            "Epoch 83/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2964\n",
            "Epoch 84/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2903\n",
            "Epoch 85/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2843\n",
            "Epoch 86/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2785\n",
            "Epoch 87/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2728\n",
            "Epoch 88/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.2672\n",
            "Epoch 89/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2617\n",
            "Epoch 90/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2563\n",
            "Epoch 91/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2510\n",
            "Epoch 92/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2459\n",
            "Epoch 93/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2408\n",
            "Epoch 94/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2359\n",
            "Epoch 95/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2310\n",
            "Epoch 96/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2263\n",
            "Epoch 97/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2216\n",
            "Epoch 98/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2171\n",
            "Epoch 99/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2126\n",
            "Epoch 100/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2083\n",
            "Epoch 101/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2040\n",
            "Epoch 102/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1998\n",
            "Epoch 103/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1957\n",
            "Epoch 104/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1917\n",
            "Epoch 105/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1877\n",
            "Epoch 106/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1839\n",
            "Epoch 107/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1801\n",
            "Epoch 108/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1764\n",
            "Epoch 109/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1728\n",
            "Epoch 110/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1692\n",
            "Epoch 111/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1658\n",
            "Epoch 112/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1624\n",
            "Epoch 113/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1590\n",
            "Epoch 114/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1558\n",
            "Epoch 115/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1526\n",
            "Epoch 116/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.1494\n",
            "Epoch 117/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1463\n",
            "Epoch 118/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1433\n",
            "Epoch 119/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1404\n",
            "Epoch 120/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1375\n",
            "Epoch 121/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1347\n",
            "Epoch 122/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1319\n",
            "Epoch 123/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1292\n",
            "Epoch 124/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1266\n",
            "Epoch 125/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1240\n",
            "Epoch 126/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1214\n",
            "Epoch 127/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1189\n",
            "Epoch 128/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1165\n",
            "Epoch 129/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1141\n",
            "Epoch 130/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1117\n",
            "Epoch 131/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1094\n",
            "Epoch 132/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1072\n",
            "Epoch 133/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1050\n",
            "Epoch 134/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1028\n",
            "Epoch 135/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1007\n",
            "Epoch 136/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0987\n",
            "Epoch 137/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0966\n",
            "Epoch 138/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0946\n",
            "Epoch 139/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0927\n",
            "Epoch 140/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0908\n",
            "Epoch 141/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0889\n",
            "Epoch 142/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0871\n",
            "Epoch 143/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0853\n",
            "Epoch 144/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0836\n",
            "Epoch 145/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0818\n",
            "Epoch 146/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0802\n",
            "Epoch 147/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0785\n",
            "Epoch 148/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0769\n",
            "Epoch 149/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0753\n",
            "Epoch 150/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0738\n",
            "Epoch 151/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0723\n",
            "Epoch 152/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0708\n",
            "Epoch 153/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0693\n",
            "Epoch 154/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0679\n",
            "Epoch 155/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0665\n",
            "Epoch 156/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0651\n",
            "Epoch 157/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0638\n",
            "Epoch 158/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0625\n",
            "Epoch 159/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0612\n",
            "Epoch 160/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0600\n",
            "Epoch 161/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0587\n",
            "Epoch 162/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0575\n",
            "Epoch 163/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0563\n",
            "Epoch 164/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0552\n",
            "Epoch 165/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0540\n",
            "Epoch 166/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0529\n",
            "Epoch 167/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0518\n",
            "Epoch 168/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0508\n",
            "Epoch 169/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0497\n",
            "Epoch 170/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0487\n",
            "Epoch 171/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0477\n",
            "Epoch 172/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0467\n",
            "Epoch 173/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0458\n",
            "Epoch 174/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0448\n",
            "Epoch 175/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0439\n",
            "Epoch 176/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0430\n",
            "Epoch 177/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0421\n",
            "Epoch 178/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0413\n",
            "Epoch 179/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0404\n",
            "Epoch 180/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0396\n",
            "Epoch 181/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0388\n",
            "Epoch 182/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0380\n",
            "Epoch 183/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0372\n",
            "Epoch 184/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0364\n",
            "Epoch 185/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0357\n",
            "Epoch 186/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0350\n",
            "Epoch 187/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0342\n",
            "Epoch 188/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0335\n",
            "Epoch 189/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0328\n",
            "Epoch 190/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0322\n",
            "Epoch 191/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0315\n",
            "Epoch 192/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0309\n",
            "Epoch 193/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0302\n",
            "Epoch 194/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0296\n",
            "Epoch 195/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0290\n",
            "Epoch 196/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0284\n",
            "Epoch 197/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0278\n",
            "Epoch 198/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0272\n",
            "Epoch 199/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0267\n",
            "Epoch 200/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0261\n",
            "Epoch 201/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0256\n",
            "Epoch 202/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0251\n",
            "Epoch 203/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0246\n",
            "Epoch 204/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0241\n",
            "Epoch 205/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0236\n",
            "Epoch 206/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0231\n",
            "Epoch 207/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0226\n",
            "Epoch 208/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0221\n",
            "Epoch 209/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0217\n",
            "Epoch 210/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0212\n",
            "Epoch 211/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0208\n",
            "Epoch 212/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0204\n",
            "Epoch 213/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0200\n",
            "Epoch 214/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0195\n",
            "Epoch 215/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0191\n",
            "Epoch 216/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0188\n",
            "Epoch 217/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0184\n",
            "Epoch 218/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0180\n",
            "Epoch 219/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0176\n",
            "Epoch 220/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0173\n",
            "Epoch 221/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0169\n",
            "Epoch 222/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0166\n",
            "Epoch 223/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0162\n",
            "Epoch 224/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0159\n",
            "Epoch 225/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0156\n",
            "Epoch 226/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0152\n",
            "Epoch 227/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0149\n",
            "Epoch 228/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0146\n",
            "Epoch 229/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0143\n",
            "Epoch 230/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0140\n",
            "Epoch 231/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0137\n",
            "Epoch 232/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0135\n",
            "Epoch 233/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0132\n",
            "Epoch 234/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0129\n",
            "Epoch 235/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0126\n",
            "Epoch 236/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0124\n",
            "Epoch 237/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0121\n",
            "Epoch 238/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0119\n",
            "Epoch 239/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0116\n",
            "Epoch 240/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0114\n",
            "Epoch 241/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0112\n",
            "Epoch 242/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0109\n",
            "Epoch 243/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0107\n",
            "Epoch 244/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0105\n",
            "Epoch 245/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0103\n",
            "Epoch 246/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0101\n",
            "Epoch 247/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0099\n",
            "Epoch 248/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0097\n",
            "Epoch 249/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0095\n",
            "Epoch 250/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0093\n",
            "Epoch 251/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0091\n",
            "Epoch 252/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0089\n",
            "Epoch 253/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0087\n",
            "Epoch 254/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0085\n",
            "Epoch 255/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0083\n",
            "Epoch 256/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0082\n",
            "Epoch 257/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0080\n",
            "Epoch 258/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0078\n",
            "Epoch 259/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0077\n",
            "Epoch 260/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0075\n",
            "Epoch 261/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0074\n",
            "Epoch 262/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0072\n",
            "Epoch 263/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0071\n",
            "Epoch 264/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0069\n",
            "Epoch 265/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0068\n",
            "Epoch 266/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0066\n",
            "Epoch 267/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0065\n",
            "Epoch 268/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0064\n",
            "Epoch 269/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0062\n",
            "Epoch 270/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0061\n",
            "Epoch 271/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0060\n",
            "Epoch 272/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0059\n",
            "Epoch 273/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0057\n",
            "Epoch 274/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0056\n",
            "Epoch 275/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0055\n",
            "Epoch 276/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0054\n",
            "Epoch 277/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0053\n",
            "Epoch 278/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0052\n",
            "Epoch 279/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0051\n",
            "Epoch 280/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0050\n",
            "Epoch 281/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0049\n",
            "Epoch 282/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0048\n",
            "Epoch 283/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0047\n",
            "Epoch 284/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0046\n",
            "Epoch 285/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0045\n",
            "Epoch 286/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0044\n",
            "Epoch 287/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0043\n",
            "Epoch 288/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0042\n",
            "Epoch 289/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0041\n",
            "Epoch 290/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0040\n",
            "Epoch 291/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0040\n",
            "Epoch 292/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0039\n",
            "Epoch 293/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0038\n",
            "Epoch 294/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0037\n",
            "Epoch 295/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0036\n",
            "Epoch 296/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0036\n",
            "Epoch 297/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0035\n",
            "Epoch 298/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0034\n",
            "Epoch 299/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0033\n",
            "Epoch 300/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0033\n",
            "Epoch 301/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0032\n",
            "Epoch 302/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0031\n",
            "Epoch 303/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0031\n",
            "Epoch 304/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0030\n",
            "Epoch 305/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0030\n",
            "Epoch 306/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0029\n",
            "Epoch 307/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0028\n",
            "Epoch 308/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0028\n",
            "Epoch 309/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0027\n",
            "Epoch 310/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0027\n",
            "Epoch 311/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0026\n",
            "Epoch 312/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0026\n",
            "Epoch 313/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0025\n",
            "Epoch 314/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0025\n",
            "Epoch 315/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0024\n",
            "Epoch 316/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0024\n",
            "Epoch 317/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0023\n",
            "Epoch 318/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0023\n",
            "Epoch 319/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0022\n",
            "Epoch 320/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0022\n",
            "Epoch 321/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0021\n",
            "Epoch 322/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0021\n",
            "Epoch 323/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0020\n",
            "Epoch 324/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0020\n",
            "Epoch 325/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0020\n",
            "Epoch 326/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0019\n",
            "Epoch 327/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0019\n",
            "Epoch 328/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0018\n",
            "Epoch 329/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0018\n",
            "Epoch 330/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0018\n",
            "Epoch 331/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0017\n",
            "Epoch 332/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0017\n",
            "Epoch 333/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0017\n",
            "Epoch 334/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0016\n",
            "Epoch 335/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0016\n",
            "Epoch 336/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0016\n",
            "Epoch 337/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0015\n",
            "Epoch 338/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0015\n",
            "Epoch 339/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0015\n",
            "Epoch 340/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0014\n",
            "Epoch 341/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0014\n",
            "Epoch 342/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0014\n",
            "Epoch 343/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0013\n",
            "Epoch 344/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0013\n",
            "Epoch 345/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0013\n",
            "Epoch 346/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0013\n",
            "Epoch 347/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0012\n",
            "Epoch 348/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0012\n",
            "Epoch 349/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0012\n",
            "Epoch 350/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0012\n",
            "Epoch 351/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0011\n",
            "Epoch 352/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0011\n",
            "Epoch 353/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0011\n",
            "Epoch 354/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0011\n",
            "Epoch 355/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0010\n",
            "Epoch 356/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0010\n",
            "Epoch 357/500\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0010\n",
            "Epoch 358/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.8428e-04\n",
            "Epoch 359/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.6407e-04\n",
            "Epoch 360/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 9.4426e-04\n",
            "Epoch 361/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.2486e-04\n",
            "Epoch 362/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 9.0587e-04\n",
            "Epoch 363/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 8.8726e-04\n",
            "Epoch 364/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.6904e-04\n",
            "Epoch 365/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 8.5119e-04\n",
            "Epoch 366/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3370e-04\n",
            "Epoch 367/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.1658e-04\n",
            "Epoch 368/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.9980e-04\n",
            "Epoch 369/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.8338e-04\n",
            "Epoch 370/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.6729e-04\n",
            "Epoch 371/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.5152e-04\n",
            "Epoch 372/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.3609e-04\n",
            "Epoch 373/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.2096e-04\n",
            "Epoch 374/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.0616e-04\n",
            "Epoch 375/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.9166e-04\n",
            "Epoch 376/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.7745e-04\n",
            "Epoch 377/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.6353e-04\n",
            "Epoch 378/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.4990e-04\n",
            "Epoch 379/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.3655e-04\n",
            "Epoch 380/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.2348e-04\n",
            "Epoch 381/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.1067e-04\n",
            "Epoch 382/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.9813e-04\n",
            "Epoch 383/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.8584e-04\n",
            "Epoch 384/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 5.7381e-04\n",
            "Epoch 385/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.6202e-04\n",
            "Epoch 386/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.5048e-04\n",
            "Epoch 387/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 5.3917e-04\n",
            "Epoch 388/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.2810e-04\n",
            "Epoch 389/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 5.1725e-04\n",
            "Epoch 390/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.0662e-04\n",
            "Epoch 391/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.9622e-04\n",
            "Epoch 392/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.8603e-04\n",
            "Epoch 393/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.7604e-04\n",
            "Epoch 394/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.6626e-04\n",
            "Epoch 395/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.5669e-04\n",
            "Epoch 396/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.4731e-04\n",
            "Epoch 397/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.3812e-04\n",
            "Epoch 398/500\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.2912e-04\n",
            "Epoch 399/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.2031e-04\n",
            "Epoch 400/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.1167e-04\n",
            "Epoch 401/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.0322e-04\n",
            "Epoch 402/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.9494e-04\n",
            "Epoch 403/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.8682e-04\n",
            "Epoch 404/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7888e-04\n",
            "Epoch 405/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.7110e-04\n",
            "Epoch 406/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.6347e-04\n",
            "Epoch 407/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.5601e-04\n",
            "Epoch 408/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.4869e-04\n",
            "Epoch 409/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.4153e-04\n",
            "Epoch 410/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.3451e-04\n",
            "Epoch 411/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.2765e-04\n",
            "Epoch 412/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.2092e-04\n",
            "Epoch 413/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.1432e-04\n",
            "Epoch 414/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.0787e-04\n",
            "Epoch 415/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.0154e-04\n",
            "Epoch 416/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.9535e-04\n",
            "Epoch 417/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.8928e-04\n",
            "Epoch 418/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.8334e-04\n",
            "Epoch 419/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 2.7752e-04\n",
            "Epoch 420/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.7182e-04\n",
            "Epoch 421/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.6624e-04\n",
            "Epoch 422/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.6077e-04\n",
            "Epoch 423/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.5541e-04\n",
            "Epoch 424/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.5016e-04\n",
            "Epoch 425/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.4503e-04\n",
            "Epoch 426/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.3999e-04\n",
            "Epoch 427/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.3507e-04\n",
            "Epoch 428/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.3024e-04\n",
            "Epoch 429/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.2551e-04\n",
            "Epoch 430/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.2088e-04\n",
            "Epoch 431/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 2.1634e-04\n",
            "Epoch 432/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.1189e-04\n",
            "Epoch 433/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.0754e-04\n",
            "Epoch 434/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.0328e-04\n",
            "Epoch 435/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.9910e-04\n",
            "Epoch 436/500\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.9501e-04\n",
            "Epoch 437/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.9101e-04\n",
            "Epoch 438/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.8708e-04\n",
            "Epoch 439/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.8324e-04\n",
            "Epoch 440/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.7948e-04\n",
            "Epoch 441/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.7579e-04\n",
            "Epoch 442/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.7218e-04\n",
            "Epoch 443/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.6864e-04\n",
            "Epoch 444/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.6518e-04\n",
            "Epoch 445/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.6179e-04\n",
            "Epoch 446/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.5846e-04\n",
            "Epoch 447/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.5521e-04\n",
            "Epoch 448/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.5202e-04\n",
            "Epoch 449/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.4890e-04\n",
            "Epoch 450/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.4584e-04\n",
            "Epoch 451/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.4284e-04\n",
            "Epoch 452/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.3991e-04\n",
            "Epoch 453/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.3704e-04\n",
            "Epoch 454/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.3422e-04\n",
            "Epoch 455/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.3146e-04\n",
            "Epoch 456/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.2876e-04\n",
            "Epoch 457/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.2612e-04\n",
            "Epoch 458/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.2353e-04\n",
            "Epoch 459/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.2099e-04\n",
            "Epoch 460/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1850e-04\n",
            "Epoch 461/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1607e-04\n",
            "Epoch 462/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1368e-04\n",
            "Epoch 463/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1135e-04\n",
            "Epoch 464/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0906e-04\n",
            "Epoch 465/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0682e-04\n",
            "Epoch 466/500\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0463e-04\n",
            "Epoch 467/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0248e-04\n",
            "Epoch 468/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0037e-04\n",
            "Epoch 469/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.8313e-05\n",
            "Epoch 470/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 9.6293e-05\n",
            "Epoch 471/500\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.4315e-05\n",
            "Epoch 472/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 9.2378e-05\n",
            "Epoch 473/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.0482e-05\n",
            "Epoch 474/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 8.8623e-05\n",
            "Epoch 475/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.6802e-05\n",
            "Epoch 476/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 8.5019e-05\n",
            "Epoch 477/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3273e-05\n",
            "Epoch 478/500\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 8.1561e-05\n",
            "Epoch 479/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.9886e-05\n",
            "Epoch 480/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.8245e-05\n",
            "Epoch 481/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.6637e-05\n",
            "Epoch 482/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.5063e-05\n",
            "Epoch 483/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.3521e-05\n",
            "Epoch 484/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.2011e-05\n",
            "Epoch 485/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.0532e-05\n",
            "Epoch 486/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.9083e-05\n",
            "Epoch 487/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.7664e-05\n",
            "Epoch 488/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.6274e-05\n",
            "Epoch 489/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.4914e-05\n",
            "Epoch 490/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.3580e-05\n",
            "Epoch 491/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.2275e-05\n",
            "Epoch 492/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.0996e-05\n",
            "Epoch 493/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.9742e-05\n",
            "Epoch 494/500\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.8515e-05\n",
            "Epoch 495/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.7314e-05\n",
            "Epoch 496/500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.6137e-05\n",
            "Epoch 497/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.4984e-05\n",
            "Epoch 498/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.3854e-05\n",
            "Epoch 499/500\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.2748e-05\n",
            "Epoch 500/500\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.1664e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f12ae3a74d0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below is a screenshot from the above code to demonstrate where a model is fit. Given a set of data, if there are too few **iterations** (epochs) of the training algorithm, the model will be **underfit** while if there are too many, the model is **overfit**."
      ],
      "metadata": {
        "id": "aWz6PWciiLQK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://github.com/hewp84/tinyml/blob/main/img/Screenshot%202022-02-10%20114507.jpg?raw=1\" width=\"480\" height=\"333\"/> <br>\n",
        "<font size='1'>Figure 4: Model Fitness<sup>2</sup></font>"
      ],
      "metadata": {
        "id": "wNTcUNIwhrUr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Underfiting** our model will be detrimental because it will not make accurate inferences on **any** data. <br> </br>\n",
        "**Overfitting** is also detrimental because the inferences will be **too good**. Meaning, given the data we provide, it will perform very well. But, when we apply our model to other data (real-world data), it will make **poor inferences**. Our model will be so highly tuned to *only* the data we gave."
      ],
      "metadata": {
        "id": "NhxG2JgRipJK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Above, there is a graph that charts how the ML minmized loss over time. \n",
        "\n",
        "Machine Learning took a **guess** at what the **rule** should be, then using **loss**, it was able to measure its **accuracy**. Depending on how accurate the guess was, it **optimized** its rule to make more guesses and bring the loss as close to zero **as possible**.\n",
        "\n"
      ],
      "metadata": {
        "id": "4fNCl8tGFZ49"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Neural Network\n",
        "The example that we utilized has a very simple neural network. It represents out linear function (y=mx+b) perfectly. The **output** represents the **predicted y-value** that the model takes a guess at. Then, fed into this function is a **weight**, the **m** value, that influences our **input**, the **x** value, and corrected by a **bias**, or, our **b** value. \n",
        "\n",
        "This linear function requires nothing more than a simple 1-node neural network.\n",
        "\n",
        "<img src=\"https://github.com/hewp84/tinyml/blob/main/img/Screenshot%202022-02-15%20103832.jpg?raw=1\" width=\"409\" height=\"177\"/> <br>\n",
        "<font size='1'>Figure 5: Neural Network<sup>1</sup></font>"
      ],
      "metadata": {
        "id": "1_dQHc5BBqI0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Results and Conclusions\n",
        "A **model** was created. We went through the process of training the model, and now it will use its defined set of **rules** (that it learned) to take input and **produce an inference**, or, a best answer that fits the input data."
      ],
      "metadata": {
        "id": "3lBJwqTrBpNJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Take the quiz on TinyML Paradigm [Quiz](2_1_TinymlParadigmQuestions.ipynb)\n",
        "\n",
        "\n",
        "Try to model more complex data sets in the [next page](Simple_Model.ipynb)"
      ],
      "metadata": {
        "id": "hMnIGKE1sBL4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br> </br>\n",
        "<br> </br>\n",
        "**References** <br>\n",
        "1: https://github.com/tinyMLx/courseware/blob/master/edX/slides/2-1-1.pdf <br>\n",
        "2: https://machinelearningmastery.com/overfitting-and-underfitting-with-machine-learning-algorithms/\n"
      ],
      "metadata": {
        "id": "QuaEwkR2ITLG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "tL_tOYdCV2PS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}